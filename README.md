This project focuses on visualizing activation maps to gain insights into how a Convolutional Neural Network (CNN) identifies and processes different facial regions when detecting emotions. 
By generating these activation maps, we can understand which parts of the image contribute the most to activating specific filters within the CNN.
